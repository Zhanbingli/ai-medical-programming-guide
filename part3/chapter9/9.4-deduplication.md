# 9.4 文献去重与智能分类

## 问题场景

**文献管理的困境**:
```
papers/
├── Smith_2024_Hypertension.pdf
├── 下载(1).pdf  ← 和上面是同一篇!
├── PMC12345678.pdf
├── nature_paper.pdf  ← 也是重复的!
└── ... 500个文件
```

**痛点**:
- 同一篇文章下载多次
- 无法快速识别重复
- 文件命名不一致导致难以发现

## 去重策略

### 方法1: 基于DOI去重(最准确)

```python
"""
DOI去重工具
"""

import pandas as pd
from pathlib import Path
import shutil

def deduplicate_by_doi(metadata_excel, action='move'):
    """
    基于DOI去重

    Args:
        metadata_excel: 元数据Excel文件(9.3节生成的)
        action: 'move' 移动重复文件, 'delete' 删除, 'report' 仅报告

    Returns:
        去重报告
    """
    print("=" * 60)
    print("文献去重工具(基于DOI)")
    print("=" * 60)

    # 读取元数据
    df = pd.read_excel(metadata_excel)

    # 只处理有DOI的文献
    df_with_doi = df[df['DOI'].notna() & (df['DOI'] != '')]

    if df_with_doi.empty:
        print("⚠️  没有找到包含DOI的文献")
        return

    print(f"\n共有{len(df_with_doi)}篇文献包含DOI")

    # 查找重复
    duplicates = df_with_doi[df_with_doi.duplicated(subset='DOI', keep='first')]

    if duplicates.empty:
        print("✓ 未发现重复文献")
        return

    print(f"⚠️  发现{len(duplicates)}篇重复文献\n")

    # 创建去重文件夹
    dup_folder = Path('duplicates')
    if action == 'move':
        dup_folder.mkdir(exist_ok=True)

    # 处理每个重复文件
    for idx, row in duplicates.iterrows():
        filename = row['Filename']
        doi = row['DOI']
        title = row['Title'][:50]

        print(f"重复: {filename}")
        print(f"  DOI: {doi}")
        print(f"  标题: {title}")

        # 找到原始文件
        original = df_with_doi[df_with_doi['DOI'] == doi].iloc[0]
        print(f"  原始文件: {original['Filename']}\n")

        # 执行操作
        file_path = Path(filename)
        if file_path.exists():
            if action == 'move':
                shutil.move(str(file_path), str(dup_folder / filename))
                print(f"  → 已移动到 duplicates/\n")
            elif action == 'delete':
                file_path.unlink()
                print(f"  → 已删除\n")

    print(f"\n✓ 去重完成!")
    print(f"  - 发现重复: {len(duplicates)}篇")
    if action == 'move':
        print(f"  - 已移动到: {dup_folder}/")

def main():
    """主程序"""
    import sys

    if len(sys.argv) < 2:
        print("用法: python deduplicate.py <元数据Excel文件> [action]")
        print("\naction选项:")
        print("  report - 仅报告重复(默认)")
        print("  move   - 移动重复文件到duplicates/")
        print("  delete - 删除重复文件")
        return

    excel_file = sys.argv[1]
    action = sys.argv[2] if len(sys.argv) > 2 else 'report'

    deduplicate_by_doi(excel_file, action)

if __name__ == "__main__":
    main()
```

### 方法2: 基于标题相似度去重

**向AI请求**:
```
有些PDF没有DOI,但标题相似(可能一个是预印本,一个是正式发表)
请添加基于标题相似度的去重
```

**AI生成代码**:
```python
from difflib import SequenceMatcher

def calculate_similarity(title1, title2):
    """
    计算两个标题的相似度

    Args:
        title1, title2: 标题字符串

    Returns:
        相似度(0-1)
    """
    # 统一小写,去除标点
    t1 = title1.lower().strip()
    t2 = title2.lower().strip()

    return SequenceMatcher(None, t1, t2).ratio()

def deduplicate_by_title(metadata_excel, threshold=0.85):
    """
    基于标题相似度去重

    Args:
        metadata_excel: 元数据Excel文件
        threshold: 相似度阈值(0.85 = 85%相似)
    """
    df = pd.read_excel(metadata_excel)

    print(f"使用标题相似度去重(阈值: {threshold})")

    duplicates_found = []

    # 两两比较
    for i in range(len(df)):
        for j in range(i + 1, len(df)):
            title1 = str(df.iloc[i]['Title'])
            title2 = str(df.iloc[j]['Title'])

            similarity = calculate_similarity(title1, title2)

            if similarity >= threshold:
                duplicates_found.append({
                    'File1': df.iloc[i]['Filename'],
                    'File2': df.iloc[j]['Filename'],
                    'Title1': title1[:50],
                    'Title2': title2[:50],
                    'Similarity': f"{similarity:.2%}"
                })

    if duplicates_found:
        print(f"\n发现{len(duplicates_found)}组相似文献:\n")
        for dup in duplicates_found:
            print(f"文件1: {dup['File1']}")
            print(f"文件2: {dup['File2']}")
            print(f"相似度: {dup['Similarity']}")
            print(f"标题1: {dup['Title1']}")
            print(f"标题2: {dup['Title2']}\n")
    else:
        print("✓ 未发现相似文献")
```

## 智能分类

### 按主题分类

**需求**:
```
将500篇文献自动分类到不同文件夹:
- Hypertension/
- Diabetes/
- Cancer/
- COVID-19/
- Others/
```

**向AI请求**:
```
实现文献自动分类功能:

输入: 文献元数据Excel
功能:
1. 根据标题和期刊名关键词识别主题
2. 创建分类文件夹
3. 移动文件到对应文件夹

关键词配置可自定义
```

**AI生成代码**:
```python
"""
文献智能分类工具
"""

import shutil
from pathlib import Path
import pandas as pd

# 分类规则配置
CATEGORIES = {
    'Hypertension': ['hypertension', 'blood pressure', 'antihypertensive'],
    'Diabetes': ['diabetes', 'glucose', 'insulin', 'glycemic'],
    'Cancer': ['cancer', 'tumor', 'oncology', 'carcinoma', 'malignancy'],
    'COVID-19': ['covid', 'coronavirus', 'sars-cov-2', 'pandemic'],
    'Cardiology': ['heart', 'cardiac', 'cardiology', 'myocardial'],
    'Neurology': ['brain', 'neurolog', 'alzheimer', 'parkinson'],
}

def classify_paper(title, journal, abstract=''):
    """
    根据内容分类文献

    Args:
        title: 标题
        journal: 期刊名
        abstract: 摘要(可选)

    Returns:
        分类名称
    """
    text = f"{title} {journal} {abstract}".lower()

    # 计算每个类别的匹配度
    scores = {}
    for category, keywords in CATEGORIES.items():
        score = sum(1 for kw in keywords if kw in text)
        if score > 0:
            scores[category] = score

    if scores:
        # 返回得分最高的类别
        return max(scores.items(), key=lambda x: x[1])[0]
    else:
        return 'Others'

def classify_literature(metadata_excel, base_folder='classified_papers'):
    """
    批量分类文献

    Args:
        metadata_excel: 元数据Excel文件
        base_folder: 分类基础文件夹
    """
    print("=" * 60)
    print("文献智能分类工具")
    print("=" * 60)

    df = pd.read_excel(metadata_excel)

    base = Path(base_folder)
    base.mkdir(exist_ok=True)

    # 创建分类文件夹
    for category in list(CATEGORIES.keys()) + ['Others']:
        (base / category).mkdir(exist_ok=True)

    # 分类统计
    classification_stats = {cat: 0 for cat in CATEGORIES.keys()}
    classification_stats['Others'] = 0

    print(f"\n开始分类{len(df)}篇文献...\n")

    for idx, row in df.iterrows():
        filename = row['Filename']
        title = str(row.get('Title', ''))
        journal = str(row.get('Journal', ''))

        # 分类
        category = classify_paper(title, journal)
        classification_stats[category] += 1

        # 移动文件
        src = Path(filename)
        if src.exists():
            dst = base / category / filename
            shutil.copy(str(src), str(dst))
            print(f"✓ {filename}")
            print(f"  → {category}/\n")

    # 打印统计
    print("=" * 60)
    print("分类统计:")
    print("=" * 60)
    for category, count in sorted(classification_stats.items(),
                                   key=lambda x: x[1], reverse=True):
        if count > 0:
            print(f"{category:15} : {count:3}篇")

    print(f"\n✓ 分类完成! 文件保存在: {base}/")

def main():
    """主程序"""
    import sys

    if len(sys.argv) < 2:
        print("用法: python classify.py <元数据Excel文件>")
        return

    classify_literature(sys.argv[1])

if __name__ == "__main__":
    main()
```

### 使用示例

```bash
# 1. 去重(仅报告)
python deduplicate.py literature_metadata.xlsx report

# 2. 去重(移动重复文件)
python deduplicate.py literature_metadata.xlsx move

# 3. 分类
python classify.py literature_metadata.xlsx
```

**输出**:
```
============================================================
文献智能分类工具
============================================================

开始分类50篇文献...

✓ Smith_2024_Hypertension.pdf
  → Hypertension/

✓ Zhang_2023_Diabetes.pdf
  → Diabetes/

============================================================
分类统计:
============================================================
Hypertension    :  15篇
Diabetes        :  12篇
Cancer          :   8篇
Cardiology      :   7篇
COVID-19        :   5篇
Others          :   3篇

✓ 分类完成! 文件保存在: classified_papers/
```

### 进阶:自定义分类规则

**向AI请求**:
```
我想自定义分类规则,从配置文件读取
格式: JSON
```

**AI生成**:
```python
import json

def load_categories(config_file='categories.json'):
    """从配置文件加载分类规则"""
    with open(config_file, 'r', encoding='utf-8') as f:
        return json.load(f)

# categories.json示例:
"""
{
  "Hypertension": {
    "keywords": ["hypertension", "blood pressure"],
    "journals": ["Hypertension", "J Hypertens"]
  },
  "Diabetes": {
    "keywords": ["diabetes", "glucose"],
    "journals": ["Diabetes Care", "Diabetologia"]
  }
}
"""
```

## 完整工作流

```
1. 下载PDF文献
   ↓
2. 提取元数据(9.3节)
   ↓
3. 基于DOI去重
   ↓
4. 基于标题去重(针对无DOI的)
   ↓
5. 智能分类
   ↓
6. 生成整理报告
```

## 检查清单

- [ ] 能识别DOI重复
- [ ] 能识别标题相似的重复
- [ ] 分类规则符合研究领域
- [ ] 生成了分类统计报告
- [ ] 原始文件有备份

## 下一步

[9.5 生成参考文献格式](9.5-citations.md) - 自动生成各种引用格式
